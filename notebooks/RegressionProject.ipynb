{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generating processes\n",
    "\n",
    "The data will come from either of two types of sources. \n",
    "\n",
    "1. Linear combination of sines and cosines\n",
    "2. Linear combination of Legendre polynomials\n",
    "\n",
    "defined on the interal $t \\in [-\\frac 1 2, +\\frac 1 2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family 1: Sines and Cosines (Fourier Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce training data\n",
    "sigma = 0.1\n",
    "n = 200\n",
    "np.random.seed(3)\n",
    "t = np.random.rand(n) - 0.5\n",
    "noise = sigma * np.random.randn(n)\n",
    "\n",
    "t = np.random.rand(n) - 0.5\n",
    "\n",
    "def fourier(t, p):\n",
    "    n = t.size\n",
    "    return np.stack(\n",
    "        [np.cos(f * 2*np.pi*t) for f in range(0, (p+1)//2)] +\n",
    "        [np.sin(f * 2*np.pi*t) for f in range(1, (p+2)//2)])\n",
    "\n",
    "p = 6   # number of features\n",
    "X = fourier(t, p)  \n",
    "theta = 0.1*np.random.randn(p)\n",
    "y = theta @ X + noise   # training data \n",
    "\n",
    "plt.plot(t, y, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family 2: Legendre Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "\n",
    "# produce training data\n",
    "\n",
    "sigma = 0.1\n",
    "n = 200\n",
    "np.random.seed(3)\n",
    "t = np.random.rand(n) - 0.5\n",
    "noise = sigma * np.random.randn(n)\n",
    "\n",
    "def legendre(t, p):\n",
    "    n = t.size\n",
    "    return np.stack(\n",
    "        [special.legendre(d)(t) for d in range(p)])\n",
    "\n",
    "p = 6  # number of features\n",
    "X = legendre(t, p)\n",
    "theta = 0.4*np.random.randn(p)\n",
    "y = theta @ X + noise   # training data \n",
    "\n",
    "plt.plot(t, y, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given observation points\n",
    "n = 200\n",
    "np.random.seed(3)\n",
    "t = np.random.rand(n) - 0.5\n",
    "\n",
    "\n",
    "#  Ground truth (HIDDEN!)\n",
    "features = fourier\n",
    "p = 11\n",
    "X = features(t, p)\n",
    "theta = [0.2, 0.7, 0.3, -0.2, 0.4, -0.5, 0.1, 0.2, 0.1, 0.5, 0.3]\n",
    "\n",
    "# Generated data based on ground truth\n",
    "y = theta @ X + 0.5*np.random.randn(n)\n",
    "\n",
    "plt.plot(t, y, '.')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')\n",
    "\n",
    "# find the ground truth\n",
    "\n",
    "\n",
    "# Hypothesize \n",
    "features = legendre\n",
    "p = 11\n",
    "X = features(t, p)\n",
    "\n",
    "# Cross-validation (one fold)\n",
    "mse = 0\n",
    "nfolds = 100\n",
    "for i in range(nfolds):\n",
    "    split = np.random.rand(n) < 0.1\n",
    "    X_train = X[:, ~split]\n",
    "    y_train = y[~split]\n",
    "    X_test = X[:, split]\n",
    "    y_test = y[split]\n",
    "\n",
    "    theta_hat = np.linalg.inv(X_train @ X_train.T) @ X_train @ y_train  # fit\n",
    "    y_predict = theta_hat @ X_test   #  predict\n",
    "\n",
    "    mse += ((y_test - y_predict)**2).mean()  # cost function\n",
    "\n",
    "print(mse/nfolds)\n",
    "\n",
    "plt.plot(t, theta_hat @ X, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = np.random.rand(n) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X @ X.T) @ X @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment \n",
    "\n",
    "Due Oct 30\n",
    "\n",
    "Given some points $(t, y)$, find the model that will predict $y$ from $t$ for new data sampled from the same process. Assume Gaussian noise. Assume that the data are \n",
    "\n",
    "The data come from one of the models above but the degree `p` is unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([-0.49,  0.48, -0.19,  0.24, -0.08,  0.49, -0.21, -0.16, -0.13,\n",
    "        0.5 ,  0.09,  0.14, -0.27,  0.01,  0.37, -0.42, -0.45, -0.14,\n",
    "        0.17,  0.14, -0.38,  0.18, -0.45, -0.3 , -0.12,  0.02, -0.11,\n",
    "        0.38, -0.01,  0.12,  0.44,  0.32,  0.2 , -0.26,  0.04,  0.23,\n",
    "        0.18,  0.14,  0.15, -0.21, -0.41,  0.06, -0.25, -0.31, -0.42,\n",
    "       -0.09,  0.34, -0.05,  0.21,  0.26,  0.27,  0.27, -0.28, -0.49,\n",
    "        0.01,  0.29, -0.15,  0.34,  0.49,  0.03, -0.12,  0.15, -0.02,\n",
    "       -0.02,  0.24,  0.47, -0.06,  0.34, -0.29, -0.43, -0.09,  0.14,\n",
    "        0.23,  0.23,  0.08,  0.12, -0.42, -0.12, -0.19,  0.45, -0.36,\n",
    "       -0.08,  0.13, -0.16,  0.23,  0.44,  0.5 , -0.3 ,  0.45, -0.24,\n",
    "       -0.42,  0.28,  0.11, -0.47,  0.11, -0.27,  0.41,  0.46, -0.36,\n",
    "       -0.32, -0.05,  0.45, -0.08, -0.39, -0.34, -0.37,  0.32, -0.24,\n",
    "       -0.44, -0.03, -0.4 ,  0.47,  0.27, -0.32, -0.2 , -0.37, -0.13,\n",
    "       -0.07,  0.08, -0.44, -0.44,  0.43, -0.04,  0.09,  0.35, -0.02,\n",
    "       -0.12,  0.42, -0.39, -0.25, -0.45,  0.44, -0.02,  0.31, -0.48,\n",
    "        0.23, -0.07, -0.17,  0.4 ,  0.35, -0.2 ,  0.45, -0.1 ,  0.17,\n",
    "        0.21, -0.11, -0.3 ,  0.48,  0.31,  0.21,  0.2 ,  0.27,  0.47,\n",
    "       -0.39,  0.46,  0.31,  0.23,  0.5 , -0.43,  0.13, -0.34,  0.02,\n",
    "       -0.27,  0.3 , -0.18,  0.41,  0.17, -0.15,  0.29, -0.05, -0.39,\n",
    "        0.25,  0.28,  0.02, -0.21,  0.11,  0.16,  0.47,  0.1 ,  0.03,\n",
    "        0.22,  0.43,  0.16, -0.21, -0.16,  0.39,  0.25,  0.04, -0.4 ,\n",
    "        0.22,  0.46,  0.12,  0.15,  0.48, -0.48, -0.15, -0.42,  0.28,\n",
    "       -0.36,  0.31])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([-0.06, -0.09, -0.19,  0.  , -0.03, -0.18, -0.12, -0.31, -0.17,\n",
    "       -0.18,  0.09,  0.16, -0.28,  0.15, -0.04,  0.04,  0.06, -0.28,\n",
    "        0.18,  0.11,  0.27,  0.34,  0.11, -0.22, -0.18,  0.39, -0.29,\n",
    "       -0.06,  0.1 ,  0.08, -0.  , -0.02,  0.06, -0.35,  0.16,  0.28,\n",
    "       -0.03,  0.17,  0.37, -0.15,  0.19,  0.21, -0.29, -0.33,  0.08,\n",
    "       -0.24,  0.06,  0.02,  0.26,  0.07,  0.1 ,  0.09, -0.52,  0.03,\n",
    "        0.3 ,  0.1 , -0.15, -0.26, -0.26,  0.1 , -0.27,  0.11,  0.02,\n",
    "        0.1 ,  0.09, -0.23, -0.03, -0.21, -0.4 , -0.04, -0.17,  0.07,\n",
    "        0.08,  0.15,  0.27,  0.41,  0.07, -0.31, -0.29, -0.3 ,  0.06,\n",
    "       -0.1 ,  0.08, -0.29,  0.07, -0.2 ,  0.06, -0.25, -0.13, -0.34,\n",
    "        0.05,  0.21,  0.07,  0.13,  0.32, -0.26, -0.01, -0.17, -0.31,\n",
    "       -0.21,  0.11, -0.1 , -0.01,  0.16, -0.01,  0.1 , -0.1 , -0.28,\n",
    "        0.08, -0.09,  0.04, -0.07, -0.11, -0.35, -0.23,  0.05, -0.25,\n",
    "       -0.12,  0.15,  0.01,  0.17,  0.02, -0.01,  0.04, -0.21,  0.03,\n",
    "       -0.15,  0.08,  0.08, -0.38,  0.19, -0.18,  0.13, -0.03,  0.1 ,\n",
    "        0.1 , -0.05, -0.29, -0.36,  0.12, -0.42, -0.32, -0.  ,  0.22,\n",
    "        0.  , -0.36, -0.33,  0.06, -0.04,  0.18, -0.08, -0.22, -0.25,\n",
    "        0.09, -0.03, -0.17,  0.02, -0.09,  0.13,  0.24, -0.04,  0.15,\n",
    "       -0.44, -0.02, -0.24,  0.09,  0.17, -0.35, -0.15, -0.1 ,  0.08,\n",
    "        0.  ,  0.09,  0.22, -0.38,  0.06,  0.14, -0.26,  0.19,  0.41,\n",
    "        0.13, -0.13,  0.3 , -0.15, -0.02, -0.09, -0.07,  0.31,  0.04,\n",
    "       -0.02, -0.05,  0.07,  0.16, -0.21,  0.01, -0.2 , -0.09,  0.11,\n",
    "        0.08, -0.  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, y, '.')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Select performance measure (cost function):  Use MSE.\n",
    "2. Implement linear regression for the two models: Assume known model and number of features p, find the parameters theta.\n",
    "3. Visualize the fit and print the training cost function.\n",
    "4. Fit with a different model and a different p.\n",
    "5. Use 10-fold cross-validation to compare models.  Measure average cross-validated MSE.  Output: best model and best `p`.\n",
    "6. (In class or evaluation) use the testing data set to test the perfomance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
